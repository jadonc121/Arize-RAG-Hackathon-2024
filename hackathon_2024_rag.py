"""Hackathon 2024 - RAG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dRSel-dyJlGvANovv4D9iSeR3wr4kdOY

# Arize Hackathon 2024 - RAG LLM with OpenInference

Description:

Create a RAG-LLM project that can read and interpret math content. LLMs are not primarily designed to be good at math. This project experiments with how an RAG performs when the external data sources are math textbooks. Can it generate mathematically logical results?

# 
"""



# Imports
import numpy as np
import pandas as pd
import requests
import base64
import phoenix as px
import chromadb
import os
import nest_asyncio

from openai import OpenAI

# Langchain imports
from langchain_community.document_loaders import PyPDFLoader # this one is better?
from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.chains import RetrievalQA

# Instrumentor imports
from openinference.instrumentation.langchain import LangChainInstrumentor
from opentelemetry import trace as trace_api
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter 
from opentelemetry.sdk import trace as trace_sdk
from opentelemetry.sdk.resources import Resource
from opentelemetry.sdk.trace.export import SimpleSpanProcessor

#------------------------------------------------------------------------
PHX = False # whether I'm sending to PHX or not
load_from_persist_db = True # T = upload vectorDB from memory, F = chunk docs and create vectorDB (take time)
verbose = True # print statements for progress
#------------------------------------------------------------------------

# PHX imports - only if I'm sending to PHX
if PHX:
  from phoenix.evals import (
      HallucinationEvaluator,
      OpenAIModel,
      QAEvaluator,
      RelevanceEvaluator,
      run_evals,
  )
  from phoenix.session.evaluation import get_qa_with_reference, get_retrieved_documents
  from phoenix.trace import DocumentEvaluations, SpanEvaluations
  from phoenix.trace.langchain import LangChainInstrumentor

from tqdm import tqdm

from arize.pandas.logger import Client

#-------------------------------------------------------------------------

# Multithreads code
nest_asyncio.apply()

# Initiate PHX session - why does this go here?
if PHX:
  session = px.launch_app()

# Optionally load and chunk docs if not already created vectorDB
# This takes a minute to run
if not load_from_persist_db:
  """# Loading and Chunking External Docs"""
  if verbose: print('Starting to load and chunk external docs')
  ## Load documents and chunk them with text splitter

  # Folder path of pdfs - need to figure out simper way, GDrive?
  #pdf_folder_path = '/content/drive/MyDrive/Hackathon 2024 RAG Docs'
  pdf_folder_path = '/Users/jadoncosta/Documents/RAG Hackathon 2024/Hackathon 2024 RAG Docs'

  # Load each pdf through loader and extend documents list
  documents = []
  for file in os.listdir(pdf_folder_path):
    pdf_path = os.path.join(pdf_folder_path, file)
    loader = PyPDFLoader(pdf_path)
    documents.extend(loader.load())

  # Create text splitter and chunk documents
  text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 0)
  chunked_docs = text_splitter.split_documents(documents)

  # Checks
  if verbose:
    print('Finished loading and chunking external docs')
    print(f'Length of chunked docs: {len(chunked_docs)}')

"""# Create embeddings and vectordatabase"""

# Create and setup OpenAI API key
os.environ["OPENAI_API_KEY"] = "[REDACTED]"
openai_api_key = os.environ.get("OPENAI_API_KEY")

## Create embeddings from vector database - Chroma

# Define local directory to save embeddings
persist_directory = 'db'
embedding = OpenAIEmbeddings()

# Creates a vectorDB unless loading one from memory
# This takes a mintue ot run
if not load_from_persist_db:
  # Create embeddings from Chroma
  vectordb = Chroma.from_documents(documents=chunked_docs,
                                  embedding = embedding,
                                  persist_directory = persist_directory)

  if verbose:
    print('Vector DB created')

  # Persist the vectordb to local device
  vectordb.persist()
  vectordb = None

# Load vectordb from disk
vectordb = Chroma(persist_directory=persist_directory,
                  embedding_function = embedding)
if verbose:
  print('Vector DB uploaded')
"""# Create Retriever Chain"""

# Create retriever
retriever = vectordb.as_retriever()

# Retrieve docs from a query
query = "How would you define a quadratic function?"
# docs = retriever.get_relevant_documents(query) # deprecated?
docs = retriever.invoke(query)
if verbose:
  docs # check

# Checks
if verbose:
  print(f'Number of docs recieved: {len(docs)}')
  print(f'How the docs were received: {retriever.search_type}')

# Create a retreival chain with OpenAI
chain_type = "stuff"
chat_model_name = "gpt-3.5-turbo"
llm = ChatOpenAI(model_name = chat_model_name)
chain = RetrievalQA.from_chain_type(llm=llm,
                                  chain_type=chain_type,
                                  retriever = retriever
                                  )

"""# Instrumentor"""
# Arize API keys
ARIZE_SPACE_KEY = "[REDACTED]"
ARIZE_API_KEY = "[REDACTED]"

# Model specifics
model_id = "rag-hackathon-2024"
model_version = "1.0"

# Set the Space and API keys as headers for authentication
headers = f"space_key={ARIZE_SPACE_KEY},api_key={ARIZE_API_KEY}"
os.environ['OTEL_EXPORTER_OTLP_TRACES_HEADERS'] = headers

# Set resource attributes for the name and version for your application
resource = Resource(
    attributes={
        "model_id":model_id, # Set this to any name you'd like for your app
        "model_version":model_version, # Set this to a version number string
    }
)

# Define the span processor as an exporter to the desired endpoint
endpoint = "https://otlp.arize.com/v1"
span_exporter = OTLPSpanExporter(endpoint=endpoint)
span_processor = SimpleSpanProcessor(span_exporter=span_exporter)

# Set the tracer provider
tracer_provider = trace_sdk.TracerProvider(resource=resource)
tracer_provider.add_span_processor(span_processor=span_processor)
trace_api.set_tracer_provider(tracer_provider=tracer_provider)

# Finish automatic instrumentation
LangChainInstrumentor().instrument()
if verbose:
  print('Instrumented!')

# Testing model
query = "How would you define a quadratic function?"
llm_response = chain.invoke(query)
print(llm_response['result'])

llm_response['result']

# Function for math RAG
def LLMathNerd(query):
  llm_response = chain.invoke(query)
  print('-'*30)
  print(query, '\n')
  print(llm_response['result'])

# Lists of example queries
# Theoreticl/Conceptual questions
queries_math_theory = [
    "What is the definition of a quadratic function?",
    "How do you solve for the zeros of a quadratic function?",
    "What's the difference between a logarithm and an exponential function?",
    "Define a nonlinear function. Give three examples.",
    "List some of the important properties of logarithms.",
    "Where do trig functions come from? How were they invented?"
]

# Hard math questions - equations, calculations, etc.
queries_math_Qs = [
    "Solve the following for x: x + 1 = 20",
    "Solve the following in terms of x: xy + 2x = 2",
    "Solve the following for x: x^2 + 2x + 1 = 0",
    "Create an example of partial fractions and solve it.",
    "Solve the following system of equations: x + y = 1, x - y = 1",
    "Determine the asymtpotes of: y = 1/(x + 2)"
]

# Run RAG function on lists of queries
for q in queries_math_theory:
  LLMathNerd(q)

for q in queries_math_Qs:
  LLMathNerd(q)

#-----------------------------------------------------------------------------------
# Only run if using phx
if PHX:
  # These export retreiver spans into dataframes
  queries_df = get_qa_with_reference(px.Client()) # single col of retrieved docs
  retrieved_docs_df = get_retrieved_documents(px.Client()) # "exploded" view of each doc

  # Checks for error with None type
  #print(type(queries_df), len(queries_df))
  #print(type(retrieved_docs_df), len(retrieved_docs_df))

  ## Create evals using evaluators with PHX

  # Define model, same chat model as above
  eval_model = OpenAIModel(model=chat_model_name)

  # Define evaluators
  hal_evaluator = HallucinationEvaluator(eval_model)
  QA_correctness_evaluator = QAEvaluator(eval_model)
  relevance_evaluator = RelevanceEvaluator(eval_model)

  # Run hallucination and QA evals, save to df
  hal_eval_df, QA_correctness_eval_df = run_evals(
      dataframe = queries_df,
      evaluators = [hal_evaluator, QA_correctness_evaluator],
      provide_explanation = True
  )

  # Run relevance evals, save to df
  relevance_eval_df = run_evals(
      dataframe = retrieved_docs_df,
      evaluators = [relevance_evaluator],
      provide_explanation = True
  )

  #retrieved_docs_df

  # Log evaluations from dataframes
  px.Client().log_evaluations(
      SpanEvaluations(eval_name="Hallucination", dataframe=hal_eval_df),
      SpanEvaluations(eval_name="QA Correctness", dataframe=QA_correctness_eval_df),
      DocumentEvaluations(eval_name="Relevance", dataframe=relevance_eval_df[0]),
  )

  # Print URL for Phoenix UI
  print(f"PHX UI: {session.url}")

  """# Sending data from PHX to Arize SDK"""

  # Save traces from PHX to dataframes
  tds = px.Client().get_trace_dataset()

  # Save spans to df
  spans_df = tds.get_spans_dataframe(include_evaluations=False)
  spans_df.head() # check

  print(f'Length of span_df: {len(spans_df)}')

  # Save evals to df
  evals_df = tds.get_evals_dataframe()
  evals_df.head() # check

  arize_client = Client(space_key=ARIZE_SPACE_KEY, api_key=ARIZE_API_KEY)
  model_id = "rag-hackathon-2024"
  model_version = "1.0"

  # Send logs to Arize
  response = arize_client.log_spans(
      dataframe=spans_df,
      evals_dataframe=evals_df,
      model_id=model_id,
      model_version=model_version,
      verbose = True
  )

  # If successful, the server will return a status_code of 200
  if response.status_code != 200:
      print(f"❌ logging failed with response code {response.status_code}, {response.text}")
  else:
      print(f"✅ You have successfully logged traces set to Arize")

